<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta
      name="description"
      content="Webpage for preprocessing images and counting rice grains."
    />
    <link rel="stylesheet" href="../css/main.css" />
    <link rel="stylesheet" href="../css/comments.css" />
    <link rel="shortcut icon" href="../Img/my_logo1.png" type="image/x-icon" />
    <title>Counting Rice Grains</title>
  </head>
  <body>
    <div class="container1">
      <div class="col-2l">
        <div class="my_github_icon">
          <a
            href="https://github.com/bluff-king"
            target="_blank"
            rel="noopener noreferrer"
          >
            <img src="../Img/github-logo.png" alt="GitHub" />
          </a>
        </div>
        <div class="my_facebook_icon">
          <a
            href="https://www.facebook.com/profile.php?id=100010165845344"
            target="_blank"
            rel="noopener noreferrer"
          >
            <img src="../Img/logo_fb.png" alt="Facebook" />
          </a>
        </div>
        <div class="my_gmail_con">
          <a href="mailto:chanthichuong@gmail.com">
            <img src="../Img/logo_gmail.png" alt="Gmail" />
          </a>
        </div>
      </div>

      <div class="col-6md">
        <header class="header-part" style="margin: 3% 0%">
          <div class="display-header">
            <h1 class="name-page">Preprocessing Image</h1>
          </div>
          <h1 class="Name-exer">Exercise1: Counting number of rice grains.</h1>
          <span class="post-date" style="color: gray; font-style: italic">
            December 25, 2024
          </span>
        </header>
        <body class="body-center">
          <div class="table-contents">
            <span><strong>In this webpage:</strong></span>
            <ol>
              <li><a href="#Introduction">Introduction</a></li>
              <li><a href="#Step-to-step">Step-to-step</a></li>
              <ul>
                <li><a href="#step1">Gray-Scale</a></li>
                <li><a href="#step2">Remove Sinusoidal Noise</a></li>
                <li><a href="#step3">Mean Filtering</a></li>
                <li><a href="#step4">Edge Detection with Canny</a></li>
                <li><a href="#step5">Opening, Closing</a></li>
                <li>
                  <a href="#step6">Line Detection with Hough Transform</a>
                </li>
                <li><a href="#step7">Remove redundant lines</a></li>
              </ul>
              <li><a href="#Evaluation">Evaluation</a></li>
              <li><a href="#Conclusion">Conclusion</a></li>
              <li><a href="#References">References</a></li>
            </ol>
          </div>

          <div class="main-content">
            <div id="Introduction">
              <h2 class="part-title">1. Introduction</h2>
              <p class="part-content">
                Given a set of chessboard images, our objective is to determine
                the size of the chessboard present in each image accurately.
                This entails identifying the arrangement and count of the
                squares that compose the chessboard layout. We kindly ask you to
                define a comprehensive processing pipeline that can be applied
                uniformly to all images within the set. This pipeline should
                encompass all necessary steps, from initial image acquisition
                and preprocessing to the final determination of the chessboard
                size. Furthermore, it is essential that all images captured from
                the same scene are processed using consistent parameter values
                whenever applicable, to ensure reliable and comparable results
                across the dataset.
              </p>
              <div class="display-images">
                <img
                  src="../Img/Exer2/Pic1.png"
                  alt="Image 1"
                  class="image-item"
                />
                <img
                  src="../Img/Exer2/Pic2.png"
                  alt="Image 2"
                  class="image-item"
                />
                <img
                  src="../Img/Exer2/Pic3.png"
                  alt="Image 3"
                  class="image-item"
                />
                <img
                  src="../Img/Exer2/Pic4.png"
                  alt="Image 4"
                  class="image-item"
                />
              </div>
            </div>

            <div id="Step-to-step">
              <h2 class="part-title">2. Step-to-step</h2>
              <p class="part-content">
                The following steps outline the preprocessing pipeline for
                determining chessboard size. Each step is designed to address
                specific challenges in the images and ensure accurate detection
                and measurement of the chessboard dimensions.
              </p>

              <div id="step1">
                <p class="part-part-title">Step 1: Gray-Scale</p>
                <p class="part-content">
                  Convert the input image to grayscale. This simplifies the
                  image by removing color information, reducing the complexity
                  of processing while preserving essential structural details.
                </p>
                <!-- <img
                  src="../Img/Exer1/GrayScale.jpg"
                  alt="Gray-Scale Example"
                  class="image-item"
                /> -->
              </div>

              <div id="step2">
                <p class="part-part-title">Step 2: Remove Sinusoidal Noise</p>
                <p class="part-content">
                  Upon observation, we notice sinusoidal noise in two of the
                  four images. To address this, we first transform the images
                  into the frequency domain using FFT and extract the magnitude
                  spectrum of all four images. <br />
                  The image with sinusoidal noise exhibits two bright points
                  along the x-axis in the frequency domain. These points are
                  carefully removed to eliminate the noise while preserving
                  critical details in the image.
                </p>

                <p class="part-content">
                  After applying a threshold to the spectrum image, we observe
                  three bright points along the x-axis. The central point,
                  however, is crucial and must be preserved. To achieve this, we
                  create a mask to protect the central point, leaving only the
                  two noise points. Using the original image, we subtract these
                  two points to remove the sinusoidal noise.
                </p>
                <!-- <img
                  src="../Img/Exer1/NoiseRemoval.jpg"
                  alt="Noise Removal Example"
                  class="image-item"
                /> -->
              </div>

              <div id="step3">
                <p class="part-part-title">Step 3: Mean Filtering</p>
                <p class="part-content">
                  Mean filtering is a simple and effective image smoothing
                  technique that helps reduce noise in an image. It works by
                  replacing each pixel's value with the average value of its
                  neighboring pixels within a specified kernel size. This
                  operation effectively smoothens the image, making it easier to
                  analyze or process further.
                </p>
                <p class="part-content">
                  The mean filter is applied by sliding a square kernel, such as
                  3x3 or 5x5, across the image and calculating the average of
                  the pixel values within the kernel at each position. This new
                  averaged value replaces the central pixel of the kernel,
                  resulting in a smoother image with less high-frequency noise.
                </p>
                <p class="part-content">
                  While mean filtering is effective at noise reduction, it can
                  also blur edges and reduce image detail. As such, it is most
                  useful in applications where preserving edges is less critical
                  or in combination with other filtering techniques to achieve
                  the desired result.
                </p>
                <!-- <img
                  src="../Img/Exer1/GammaCorrection.jpg"
                  alt="Gamma Correction Example"
                  class="image-item"
                /> -->
              </div>

              <div id="step4">
                <p class="part-part-title">Step 4: Edge Detection with Canny</p>
                <p class="part-content">
                  In this step, we use the Canny edge detection algorithm to
                  identify the edges in the image. Canny is a popular method due
                  to its ability to detect edges with precision while minimizing
                  noise and false positives.
                </p>
                <p class="part-content">
                  The Canny algorithm works in several stages: it applies
                  Gaussian smoothing to reduce noise, computes gradients to
                  highlight regions with high intensity changes, and uses
                  non-maximum suppression to remove weak edges. Finally, double
                  thresholding and edge tracking are performed to connect edge
                  segments and retain only significant edges.
                </p>
                <div class="display-images">
                  <img
                    src="../Img/Exer2/edges_image_1.png"
                    alt="Image 1"
                    class="image-item"
                  />
                  <img
                    src="../Img/Exer2/edges_image_2.png"
                    alt="Image 2"
                    class="image-item"
                  />
                  <img
                    src="../Img/Exer2/edges_image_3.png"
                    alt="Image 3"
                    class="image-item"
                  />
                  <img
                    src="../Img/Exer2/edges_image_4.png"
                    alt="Image 4"
                    class="image-item"
                  />
                </div>
              </div>

              <div id="step5">
                <p class="part-part-title">Step 5: Opening, Closing</p>
                <p class="part-content">
                  Morphological operations such as opening and closing are
                  applied in this step to refine the shapes of the detected
                  objects. These techniques help remove noise, fill small gaps
                  within objects, and connect fragmented edges into more unified
                  lines.
                </p>
                <p class="part-content">
                  The opening operation, which involves erosion followed by
                  dilation, removes small noise points, while the closing
                  operation, a dilation followed by erosion, bridges small gaps
                  in the edges. Together, they enhance the clarity and
                  continuity of the lines in the image.
                </p>
                <p class="part-content">
                  By carefully calibrating the size of the structuring element
                  used in these operations, the refined lines can be kept small
                  enough to ensure accurate line-drawing without excessive
                  overlaps or extensions. This step is essential for maintaining
                  precision in subsequent processes.
                </p>
              </div>

              <div id="step6">
                <p class="part-part-title">
                  Step 6: Line Detection with Hough Transform
                </p>
                <p class="part-content">
                  In this step, the Hough Transform is used to detect straight
                  lines in the image. This method works by transforming points
                  in the image space into a parameter space defined by two
                  values: <em>rho</em>, the distance from the origin to the
                  line, and <em>theta</em>, the angle of the line. Each point in
                  the image votes for potential lines, and lines with enough
                  votes are identified as significant.
                </p>
                <p class="part-content">
                  Tuning the parameters for the Hough Transform, including the
                  resolution of <em>rho</em> and <em>theta</em>, as well as the
                  minimum number of votes required to confirm a line, is
                  crucial. Multiple tests may be necessary to find the best
                  combination that accurately captures the desired lines while
                  minimizing false detections.
                </p>
                <div class="display-images">
                  <img
                    src="../Img/Exer2/hough_lines_image_1.png"
                    alt="Image 1"
                    class="image-item"
                  />
                  <img
                    src="../Img/Exer2/hough_lines_image_2.png"
                    alt="Image 2"
                    class="image-item"
                  />
                  <img
                    src="../Img/Exer2/hough_lines_image_3.png"
                    alt="Image 3"
                    class="image-item"
                  />
                  <img
                    src="../Img/Exer2/hough_lines_image_4.png"
                    alt="Image 4"
                    class="image-item"
                  />
                </div>
              </div>
              <div id="step7">
                <p class="part-part-title">Step7: Remove redundant lines</p>
                <p class="part-content">
                  After detecting lines using the Hough Transform, redundant
                  lines are removed to improve clarity and reduce overlap. Lines
                  are considered redundant if their <em>rho</em> (distance from
                  the origin) and <em>theta</em> (angle) values are too close to
                  one another. These similar lines often represent the same
                  structure in the image and can clutter the output.
                </p>
                <p class="part-content">
                  To eliminate these duplicates, the lines are compared
                  pairwise, and those with differences in <em>rho</em> or
                  <em>theta</em> below a predefined threshold are merged or
                  removed. This step ensures that only distinct and meaningful
                  lines are retained, creating a cleaner and more accurate
                  representation of the imageâ€™s structure.
                </p>
                <div class="display-images">
                  <img
                    src="../Img/Exer2/filtered_lines_image_1.png"
                    alt="Image 1"
                    class="image-item"
                  />
                  <img
                    src="../Img/Exer2/filtered_lines_image_2.png"
                    alt="Image 2"
                    class="image-item"
                  />
                  <img
                    src="../Img/Exer2/filtered_lines_image_3.png"
                    alt="Image 3"
                    class="image-item"
                  />
                  <img
                    src="../Img/Exer2/filtered_lines_image_4.png"
                    alt="Image 4"
                    class="image-item"
                  />
                </div>
              </div>
            </div>

            <div id="Evaluation">
              <h2 class="part-title">3. Evaluation</h2>
              <p class="part-content">
                The evaluation results show that each image is expected to have
                11 vertical lines and 7 horizontal lines. Adding 1 to these
                counts should give the chessboard dimensions as 12 and 8.
                However, the number of detected lines for each image is as
                follows:
              </p>
              <ul>
                <li>
                  <strong>Image 1:</strong> Vertical lines (filtered): 13,
                  Horizontal lines (filtered): 7
                </li>
                <li>
                  <strong>Image 2:</strong> Vertical lines (filtered): 13,
                  Horizontal lines (filtered): 7
                </li>
                <li>
                  <strong>Image 3:</strong> Vertical lines (filtered): 14,
                  Horizontal lines (filtered): 7
                </li>
                <li>
                  <strong>Image 4:</strong> Vertical lines (filtered): 14,
                  Horizontal lines (filtered): 7
                </li>
              </ul>
              <p class="part-content">
                The horizontal lines are detected correctly in all cases.
                However, for the vertical lines, some issues are observed. The
                Hough Transform sometimes identifies two lines on either side of
                a main line, leading to extra detections. Additionally, some
                vertical lines are missed. As a result, the final counts for
                vertical lines are 13 or 14 instead of the expected 11.
              </p>
            </div>
            <div id="Conclusion">
              <h2 class="part-title">4. Conclusion</h2>
              <p class="part-content">
                After experimenting with different parameter values, we obtained
                the following settings for the main steps below. While the
                results are acceptable, they are not yet perfect. In the future,
                we plan to explore further improvements to accurately determine
                the true size and structure of the chessboard.
              </p>
              <ul>
                <li>
                  <p>
                    cv2.resize(image, (461, 461), interpolation=cv2.INTER_AREA)
                  </p>
                </li>
                <li><p>cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)</p></li>
                <li><p>cv2.medianBlur(remove_stripes[i], 5)</p></li>
                <li>
                  <p>
                    cv2.Canny(spp_removal_image[i], threshold1=50,
                    threshold2=100)
                  </p>
                </li>
                <li>
                  <p>
                    cv2.dilate(edges_images[i], np.ones((5, 5), np.uint8),
                    iterations=2)
                  </p>
                </li>
                <li>
                  <p>
                    cv2.erode(dilated, np.ones((3, 3), np.uint8), iterations=3)
                  </p>
                </li>
                <li>
                  <p>
                    cv2.HoughLines(edges, rho=0.75, theta=np.pi/180,
                    threshold=150)
                  </p>
                </li>
              </ul>
            </div>
            <div id="References">
              <h2 class="part-title">5. References</h2>
              <p class="part-content">
                We sincerely thank Hanoi University and the Computer Vision Lab
                for their valuable support in providing resources and materials
                for this work. Their commitment to research and collaboration
                has played an important role in shaping this project. The
                resources and guidance from the Computer Vision Lab have greatly
                enhanced our understanding and contributed to the success of
                this work.
              </p>
            </div>
          </div>
        </body>

        <div class="section">
          <div class="comments">
            <script>
              const commentsPageId = 1;
              const commentsTable = "cmt_p2";
              fetch(
                `../php/comments.php?page_id=${commentsPageId}&table=${commentsTable}`
              )
                .then((response) => response.text())
                .then((data) => {
                  document.querySelector(".comments").innerHTML = data;
                  document
                    .querySelectorAll(
                      ".comments .write_comment_btn, .comments .reply_comment_btn"
                    )
                    .forEach((element) => {
                      element.onclick = (event) => {
                        event.preventDefault();
                        document
                          .querySelectorAll(".comments .write_comment")
                          .forEach(
                            (element) => (element.style.display = "none")
                          );
                        document.querySelector(
                          "div[data-comment-id='" +
                            element.getAttribute("data-comment-id") +
                            "']"
                        ).style.display = "block";
                        document
                          .querySelector(
                            "div[data-comment-id='" +
                              element.getAttribute("data-comment-id") +
                              "'] input[name='name']"
                          )
                          .focus();
                      };
                    });
                  document
                    .querySelectorAll(".comments .write_comment form")
                    .forEach((element) => {
                      element.onsubmit = (event) => {
                        event.preventDefault();
                        fetch(
                          `../php/comments.php?page_id=${commentsPageId}&table=${commentsTable}`,
                          {
                            method: "POST",
                            body: new FormData(element),
                          }
                        )
                          .then((response) => response.text())
                          .then((data) => {
                            element.parentElement.innerHTML = data;
                          });
                      };
                    });
                });
            </script>
          </div>
        </div>
      </div>
      <div class="col-2r">
        <hr />
        <div class="share">
          <p style="padding-left: 4%; font-size: 2rem; margin: 0px">SHARE</p>
          <div class="share-icon">
            <img
              src="../Img/logo_fb.png"
              alt="Facebook Logo"
              style="cursor: pointer"
              onclick="window.open('https://www.facebook.com/sharer/sharer.php?u=https://example.com', '_blank', 'noopener,noreferrer')"
            />
            <img
              src="../Img/logo_gmail.png"
              alt="Gmail Logo"
              style="cursor: pointer"
              onclick="window.open('mailto:?subject=Check%20this%20out!&body=Hi,%0A%0ACheck%20out%20this%20link:%20https://example.com', '_self')"
            />
            <img
              src="../Img/print.png"
              alt="Print Icon"
              onclick="window.print()"
            />
          </div>
        </div>
        <hr />
        <div class="related-exer">
          <div class="item">
            <a href="./Page1.html">
              <img src="../Img/rice_grains.png" alt="Rice grains counting" />
              <h2 class="related-title">Counting Rice Grains</h2>
            </a>
          </div>
          <div class="item">
            <a href="./Page2.html">
              <img src="../Img/exer2.png" alt="Chessboard size" />
              <h2 class="related-title">Determining Chessboard Size</h2>
            </a>
          </div>
          <div class="item">
            <a href="./Page3.html">
              <img src="../Img/exer3.png" alt="" />
              <h2 class="related-title">
                Tracking Historical Moves of Chess Match
              </h2>
            </a>
          </div>
        </div>
      </div>
    </div>
  </body>
</html>
